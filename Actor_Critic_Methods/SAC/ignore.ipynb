{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, alpha, input_dims, fc1_dims, fc2_dims, max_action,\n",
    "            n_actions, name, chkpt_dir='tmp/sac'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.name = name\n",
    "        self.max_action = max_action\n",
    "        self.checkpoint_dir = chkpt_dir\n",
    "        self.checkpoint_file = os.path.join(self.checkpoint_dir, name+'_sac')\n",
    "        self.reparam_noise = 1e-6\n",
    "\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.mu = nn.Linear(self.fc2_dims, self.n_actions)\n",
    "        self.sigma = nn.Linear(self.fc2_dims, self.n_actions)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        prob = self.fc1(state)\n",
    "        prob = F.relu(prob)\n",
    "        prob = self.fc2(prob)\n",
    "        prob = F.relu(prob)\n",
    "\n",
    "        mu = self.mu(prob)\n",
    "        sigma = self.sigma(prob)\n",
    "        sigma = T.clamp(sigma, min=-20, max=2) # sigma = T.clamp(sigma, min=self.reparam_noise, max=1) \n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def sample_normal(self, state, reparameterize=True):\n",
    "        mu, sigma = self.forward(state)\n",
    "        probabilities = T.distributions.Normal(mu, sigma)\n",
    "\n",
    "        if reparameterize:\n",
    "            actions = probabilities.rsample() # reparameterizes the policy\n",
    "        else:\n",
    "            actions = probabilities.sample()\n",
    "\n",
    "        action = T.tanh(actions)*T.tensor(self.max_action).to(self.device) \n",
    "        log_probs = probabilities.log_prob(actions)\n",
    "        log_probs -= T.log(1-action.pow(2) + self.reparam_noise)\n",
    "        log_probs = log_probs.sum(1, keepdim=True)\n",
    "\n",
    "        return action, log_probs\n",
    "\n",
    "    def sample_mvnormal(self, state, reparameterize=True):\n",
    "        \"\"\"\n",
    "            Doesn't quite seem to work.  The agent never learns.\n",
    "        \"\"\"\n",
    "        mu, sigma = self.forward(state)\n",
    "        n_batches = sigma.size()[0]\n",
    "\n",
    "        cov = [sigma[i] * T.eye(self.n_actions).to(self.device) for i in range(n_batches)]\n",
    "        cov = T.stack(cov)\n",
    "        probabilities = T.distributions.MultivariateNormal(mu, cov)\n",
    "\n",
    "        if reparameterize:\n",
    "            actions = probabilities.rsample() # reparameterizes the policy\n",
    "        else:\n",
    "            actions = probabilities.sample()\n",
    "\n",
    "        action = T.tanh(actions) # enforce the action bound for (-1, 1)\n",
    "        log_probs = probabilities.log_prob(actions)\n",
    "        log_probs -= T.sum(T.log(1-action.pow(2) + self.reparam_noise))\n",
    "        log_probs = log_probs.sum(-1, keepdim=True)\n",
    "\n",
    "        return action, log_probs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "act = ActorNetwork(0.1, (4,), 256, 256, 10, 2, 'actor')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "x = T.rand((32, 4))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "act.forward(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 0.0344, -0.0445],\n",
       "         [ 0.0829,  0.0051],\n",
       "         [ 0.0970, -0.0068],\n",
       "         [ 0.0766, -0.0238],\n",
       "         [ 0.1017, -0.0137],\n",
       "         [ 0.0328, -0.0363],\n",
       "         [ 0.0680, -0.0656],\n",
       "         [ 0.0219, -0.0494],\n",
       "         [ 0.0557, -0.0251],\n",
       "         [ 0.0741, -0.0268],\n",
       "         [ 0.0509, -0.0204],\n",
       "         [ 0.1077,  0.0048],\n",
       "         [ 0.1028, -0.0145],\n",
       "         [ 0.1087, -0.0030],\n",
       "         [ 0.0233, -0.0574],\n",
       "         [ 0.0518, -0.0466],\n",
       "         [ 0.0712,  0.0016],\n",
       "         [ 0.0949, -0.0205],\n",
       "         [ 0.0727, -0.0095],\n",
       "         [ 0.0764, -0.0144],\n",
       "         [ 0.0918,  0.0023],\n",
       "         [ 0.0823, -0.0169],\n",
       "         [ 0.0890, -0.0467],\n",
       "         [ 0.0381, -0.0457],\n",
       "         [ 0.0806,  0.0118],\n",
       "         [ 0.0350, -0.0481],\n",
       "         [ 0.0553, -0.0658],\n",
       "         [ 0.0995,  0.0071],\n",
       "         [ 0.1015, -0.0335],\n",
       "         [ 0.0850,  0.0007],\n",
       "         [ 0.0905,  0.0001],\n",
       "         [ 0.0401, -0.0427]], grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.0315,  0.0717],\n",
       "         [-0.0498,  0.0792],\n",
       "         [-0.0050,  0.0752],\n",
       "         [-0.0116,  0.0554],\n",
       "         [ 0.0194,  0.0711],\n",
       "         [ 0.0066,  0.0695],\n",
       "         [ 0.0007,  0.0537],\n",
       "         [-0.0297,  0.0787],\n",
       "         [ 0.0037,  0.0715],\n",
       "         [-0.0099,  0.0596],\n",
       "         [-0.0235,  0.0670],\n",
       "         [-0.0437,  0.0880],\n",
       "         [ 0.0138,  0.0810],\n",
       "         [ 0.0148,  0.0737],\n",
       "         [-0.0368,  0.0741],\n",
       "         [-0.0251,  0.0623],\n",
       "         [-0.0071,  0.0849],\n",
       "         [ 0.0202,  0.0607],\n",
       "         [-0.0091,  0.0706],\n",
       "         [-0.0105,  0.0653],\n",
       "         [-0.0402,  0.0804],\n",
       "         [-0.0056,  0.0611],\n",
       "         [ 0.0157,  0.0660],\n",
       "         [-0.0241,  0.0674],\n",
       "         [-0.0559,  0.0658],\n",
       "         [-0.0474,  0.0774],\n",
       "         [-0.0041,  0.0594],\n",
       "         [-0.0183,  0.0723],\n",
       "         [ 0.0313,  0.0703],\n",
       "         [-0.0363,  0.0777],\n",
       "         [ 0.0195,  0.0916],\n",
       "         [-0.0257,  0.0726]], grad_fn=<ClampBackward1>))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "d0f26032d3dba47d9287cbbbb387c9fd50da3d0deb74c641199a99306a820733"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}